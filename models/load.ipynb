{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use DataParallel for Generator and Discriminator\n"
     ]
    }
   ],
   "source": [
    "from cprogan import ConditionalProGAN\n",
    "import torch as th\n",
    "\n",
    "START_DEPTH = 4\n",
    "latent_size = 256\n",
    "depth = 7\n",
    "device = th.device('cuda') if th.cuda.is_available() else th.device('cpu')\n",
    "name = 'd3_env'\n",
    "\n",
    "log_dir =    f'../output/{name}/logs/'\n",
    "sample_dir = f'../output/{name}/samples/'\n",
    "save_dir =   f'../output/{name}/models/'\n",
    "pro_gan = ConditionalProGAN(num_classes=3 ,depth=depth, latent_size=latent_size, use_ema=True, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_gan.reload(start_depth=START_DEPTH, save_dir=save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,\n",
      "        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,\n",
      "        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,\n",
      "        0, 1, 2, 0, 1, 2, 0, 1, 2], device='cuda:0')\n",
      "<PIL.Image.Image image mode=L size=596x596 at 0x1F761935360>\n",
      "<PIL.Image.Image image mode=RGB size=596x596 at 0x1F761935F00>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "\n",
    "sample_num = 81\n",
    "\n",
    "input_noize = th.randn(sample_num, latent_size).to(device)\n",
    "input_label = th.as_tensor([i%3 for i in range(sample_num)]).to(device)\n",
    "print(input_label)\n",
    "\n",
    "sample =pro_gan.print(input_noize, input_label, START_DEPTH, 1)\n",
    "from torchvision.utils import save_image\n",
    "save_image(sample, 'tmp.png', nrow=int(np.sqrt(len(sample))),\n",
    "                   normalize=True, scale_each=True)\n",
    "from PIL import Image\n",
    "rgba_img = Image.open('tmp.png')\n",
    "\n",
    "gray_img  = rgba_img.convert(\"L\")\n",
    "\n",
    "rgba_arr = np.array(rgba_img)\n",
    "\n",
    "gray_arr = np.array(gray_img)\n",
    "\n",
    "for row in range(rgba_arr.shape[0]):\n",
    "    for col in range(rgba_arr.shape[1]):\n",
    "        gray_arr[row][col] = rgba_arr[row][col][3]\n",
    "        rgba_arr[row][col][3] = 1\n",
    "\n",
    "im = Image.fromarray(gray_arr)\n",
    "print(im)\n",
    "im.save('dem.png')\n",
    "im = Image.fromarray(rgba_arr)\n",
    "im = im.convert('RGB')\n",
    "print(im)\n",
    "im.save('sat.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0857cb0f6eaafc429a144dff2c8ec99ab87e307df337c6e8cac39982794126bb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\No\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from cprogan import  ConditionalProGAN, setup_data, IN_CHANNEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1660 SUPER\n",
      "batch_sizes: [8, 8, 8, 8, 8, 8, 8]\n",
      "data num:8192\n",
      "torch.Size([4, 256, 256])\n",
      "channel: 4\n",
      "use DataParallel for Generator and Discriminator\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import os\n",
    "\n",
    "# select the device to be used for training\n",
    "device = th.device('cuda') if th.cuda.is_available() else th.device('cpu')\n",
    "print(th.cuda.get_device_name(device)) # \n",
    "\n",
    "name = 'd3_env'\n",
    "output_path = f'../output/{name}'\n",
    "\n",
    "if not os.path.exists(f'{output_path}'):\n",
    "    os.makedirs(f'{output_path}')\n",
    "\n",
    "log_dir =    f'{output_path}/logs/'\n",
    "sample_dir = f'{output_path}/samples/'\n",
    "save_dir =   f'{output_path}/models/'\n",
    "\n",
    "data_path = '../data/RGBA256'\n",
    "\n",
    "# some parameters:\n",
    "depth = 7\n",
    "START_DEPTH = 5\n",
    "START_EPOCH = 51\n",
    "# hyper-parameters per depth (resolution)\n",
    "             # 4x4, 8x8, 16x16, 32x32, 64x64, 128x128, 256x256\n",
    "num_epochs = [20,   20,   40,   80,    80,    80,      100]\n",
    "fade_ins = [10, 20, 30, 40, 50, 100, 100]\n",
    "batch_sizes = depth*[8]\n",
    "print(\"batch_sizes:\" , batch_sizes)\n",
    "latent_size = 256\n",
    "# get the data. Ignore the test data and their classes\n",
    "dataset= setup_data(data_path, size= latent_size, num = 1024*8)\n",
    "print(f'data num:{len(dataset)}')\n",
    "print(dataset[0][0].shape)\n",
    "IN_CHANNEL= dataset[0][0].shape[0]\n",
    "print(f\"channel: {IN_CHANNEL}\")\n",
    "\n",
    "\n",
    "pro_gan = ConditionalProGAN(num_classes=3, depth=depth, latent_size=latent_size, device=device)\n",
    "# ======================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--reload model--\n",
      "seed:  284844028838400\n",
      "Starting the training process ... \n",
      "\n",
      "\n",
      "Currently working on Depth:  5\n",
      "Current resolution: 128 x 128\n",
      "Ticker 51200\n",
      "\n",
      "Epoch: 51\n"
     ]
    }
   ],
   "source": [
    "pro_gan.train(\n",
    "    dataset=dataset,\n",
    "    epochs=num_epochs,\n",
    "    fade_in_percentage=fade_ins,\n",
    "    batch_sizes=batch_sizes,\n",
    "    start_epoch= START_EPOCH,\n",
    "    start_depth= START_DEPTH,\n",
    "    save_dir=save_dir,\n",
    "    log_dir=log_dir,\n",
    "    sample_dir=sample_dir\n",
    ")\n",
    "# seed:  205080318906200\n",
    "# seed:  232798884807900"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0857cb0f6eaafc429a144dff2c8ec99ab87e307df337c6e8cac39982794126bb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
